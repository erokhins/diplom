\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\inputencoding{utf8}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}

\newcommand{\Expect}{\mathbb E}
\newcommand{\PRob}{\mathbb P}
\newcommand{\leqs}{\leqslant}
\newcommand{\geqs}{\geqslant}
\newcommand{\eps}{\varepsilon}

\newtheorem{theorem}{Теорема}
\newtheorem{note}{Замечание}
\newtheorem{cons}{Следствие}
\newtheorem{define}{Определение}
\newtheorem{lemma}{Лемма}

\newtheoremstyle{named}{}{}{\itshape}{}{\bfseries}{.}{.5em}{#1 #3}
\theoremstyle{named}
\newtheorem*{namedtheorem}{Теорема}
\newtheorem*{namedpropo}{}

\begin{document}
\section{Основные определения}
В рамках этой дипломной работы мы будем иметь дело только с двудольными графами доли которых мы условно назовём клиенты и фрагменты.
Ребро между некоторым клиентом и фрагментом будет означать, что данный клиент скачал данный фрагмент.
Обозначим количество клиентов за $n$, а количество фрагментов за $N$. В рамках данной работы, будем предполагать, что $n, N \geqs 100$.
Заметим, что максимальное возможное количество рёбер в таком графе $nN$.

Пусть дан произвольный двудольный граф $G$. Определим для него несколько функций:
\begin{align*}
&E(G) \text{ --- количество рёбер}\\
&Q(G) \text{ --- минимальная степень фрагмента}
\end{align*}
Нас будет интересовать, как ведёт себя функция $Q(G)$ при различных моделях роста графа $G$.

\begin{define}
Некоторое свойство графа будем называть монотонным, если оно сохраняется при добавлении рёбер.
\end{define}

\begin{note}
Пусть $k$ -- натуральное число. Тогда свойство $Q(G) > k$ является монотонным свойством.
\end{note}

Также сформулируем некоторые известные теоремы, которыми мы будем пользоваться.
\begin{namedtheorem}[Чернова] (Для бернуллиевских случайных величин) \label{Cher} 

Пусть у нас есть $X_1, X_2, X_3, \dots X_n$ -- 
независимые бернуллиевские случайные величины(не обязательно одинаково распределенные). Пусть $X = \sum\limits_{i = 1}^n X_i$ и
$\mu = \Expect X$, также пусть $\delta > 0$. Тогда выполняются следующие неравенства:

\begin{align}
\PRob[X < (1-\delta)\mu] &< \exp\left(- \frac{\mu \delta^2}{2} \right)
\\
\PRob[X > (1+\delta)\mu] &< \exp\left(- \frac{\mu \delta^2}{4} \right) \text{, при } \delta < 2e - 1
\end{align}
\end{namedtheorem}
Доказательство этой теоремы можно найти в статье \cite{chernov}.

\begin{namedpropo}[Граница Чернова] (Для пуассоновской случайной величины)

Пусть $X$ -- пуассоновская случайная величина с показателем $\lambda$, тогда верны следующие неравенства:
\begin{align} \label{gr_1}
\PRob(X \geqs x) \leqs \frac{e^{-\lambda}(e\lambda)^x}{x^x}, \text{ для всех } x > \lambda 
\\
\label{gr_2}
\PRob(X \leqs x) \leqs \frac{e^{-\lambda}(e\lambda)^x}{x^x}, \text{ для всех } x < \lambda 
\end{align}
\end{namedpropo}
Доказательство этого утверждения можно найти в \cite{chernov_gr}.

\section{Модель 1. Равномерный выбор рёбер.}
В этой модели граф будет расти следующим образом: на каждом шагу мы равномерно выбираем произвольное ещё не проведённое ребро 
и проводим его. Обозначим за $G_m$ граф, который получается на $m$-том шагу. Ясно, что $E(G_m) = m$.
Выберем некоторое число $q \in (0, 1)$ и зададимся вопросом, насколько велико должно быть $m$, чтобы выполнялось: $Q(G_m) > qn$.
К сожалению, исследовать граф $G_m$ напрямую не очень удобно, поэтому мы создадим некоторый граф, который будет похож на граф $G_m$.

Создадим граф $H_p$, где $p \in [0, 1]$, который будет построен по следующему правилу: 
разыгрываем $nN$ бернуллиевских случайных величин $I_{1,1}, I_{1,2}, \dots I_{n,N}$ с показателем $p$ и проводим ребро от $k$-го клиента к $K$ фрагменту, 
если $I_{k, K} = 1$.
Заметим, что случайный граф $G_m$ устроен следующим образом: все графы, в которых ровно $m$ рёбер, выпадают с одинаковой вероятностью.
А если взять граф $H_p$ при условии того, что $E(H_p) = m$, то тогда он устроен так же, как и $G_m$.
Это позволит нам доказать следующую лемму:

%лемма 1
\begin{lemma} \label{l1}
Пусть $A$ - множество всех графов, который обладают некоторым монотонным свойством, а $\delta \in (0,1)$.
Тогда, если $\PRob( H_p \in A) \geqs 1 - \eps$, то
\begin{equation} \label{l1_1}
\PRob(G_{\lceil pnN(1+\delta) \rceil} \in A) > 1 - \frac{\eps}{1 - \exp\left(-\frac{\delta^2}{4}pnN\right)};
\end{equation}
a если $\PRob( H_p \in A) \leqs \eps$, то
\begin{equation}\label{l1_2}
\PRob(G_{\lfloor pnN(1-\delta) \rfloor} \in A) < \frac{\eps}{1 - \exp\left(-\frac{\delta^2}{2}pnN\right)};
\end{equation}
\end{lemma}

\begin{proof}
Будем доказывать неравенство (\ref{l1_1}). Заметим, что 
\begin{equation}
E(H_p) = \sum_{k=1}^n \sum_{K=1}^N I_{k, K},
\end{equation}
где $I_{k,K}$ -- бернуллиевские случайные величины с показателем $p$.
Применим к $E(H_p)$ теорему Чернова, где $\mu = \Expect(E(H_p) = pnN$, а $\delta$ взята из условия леммы.
Получим следующее неравенство:
\begin{equation}\label{l1_3}
\PRob\big( E(H_p) \leqs pnN(1+\delta) \big) > 1 - \exp\left(-\frac{\delta^2}{4}pnN\right).
\end{equation}
Заметим, что $m = \lceil pnN(1+\delta) \rceil \geqs pnN(1+\delta)$, а значит
\begin{equation}\label{l1_4}
\PRob\big( E(H_p) \leqs m \big) \geqs \PRob\big( E(H_p) \leqs pnN(1+\delta) \big)
\end{equation}
Положим $B = \PRob\Big( H_p \in A \big| E(H_p) \leqs m \Big)$. Заметим, что
\begin{equation}\label{l1_big}
\begin{aligned}
B = \frac{
		\PRob\Big( H_p \in A \bigcap E(H_p) \leqs m \Big)
	}{
		\PRob\big(E(H_p) \leqs m \big)
	} 
&\geqs 
	\frac{
		\PRob\big(E(H_p) \leqs m \big) 
			-
		\PRob\big(H_p \not\in A \big)
	}{
		\PRob\big(E(H_p) \leqs m\big)
	}
=
\\
=
	1 
		-
	\frac{
		\PRob\big(H_p \not\in A \big)
	}{
		\PRob\big(E(H_p) \leqs m\big)
	}
&>
	1
		-
	\frac{\eps}{
		1 - \exp\left(-\frac{\delta^2}{4}pnN\right)
	},
\end{aligned}\end{equation}
где в последнем переходе мы воспользовались неравенствами (\ref{l1_3}), (\ref{l1_4}) 
и неравенством $\PRob\big(H_p \not\in A \big) < \eps$, которое очевидно из условия леммы.
Теперь докажем, что $\PRob(G_{\lceil pnN(1+\delta) \rceil} \in A) \geqs B$.

Рассмотрим граф $H_p$ при условии того, что $E(H_p) \leqs m$ и обозначим его $H_p^m$. 
Заметим, что этот граф удовлетворяет свойству $A$ с вероятностью $B$, а $E(H_p^m) \leqs m$.
Теперь мы несколько раз добавим ребер в этот граф, пока в нем не станет ровно $m$ ребер, 
при этом на каждом шагу ребра будем выбирать равномерно.
\\
Заметим, что мы получим случайный граф, в котором ровно $m$ ребер. Несложно понять, 
что этот граф по распределению совпадает с $G_m$, т.к. мы нигде не различали рёбра между собой, а значит они перестановочны.
При этом мы знаем, что граф $H_p^m$, с которого мы начинали, обладал свойством $A$ с вероятностью $B$, 
а значит $\PRob(G_m \in A) \geqs B$. Применяя неравенство (\ref{l1_big}) получаем (\ref{l1_1}).

Теперь докажем (\ref{l1_2}). Пусть $l = \lfloor pnN(1-\delta) \rfloor$. Аналогично неравенствам (\ref{l1_3}) и (\ref{l1_4}) получаем
\begin{equation} \label{l1_5}
\PRob\big( E(H_p) \geqs l \big) > 1 - \exp\left(-\frac{\delta^2}{2}pnN\right).
\end{equation}
После этого получаем аналог неравенства (\ref{l1_big})
\begin{equation}\label{l1_big2}
\begin{aligned}
	\PRob\Big( H_p \not\in A \big| E(H_p) \geqs l \Big)
=
	\frac{
		\PRob\Big( H_p \not\in A \bigcap E(H_p) \geqs l \Big)
	}{
		\PRob\big(E(H_p) \geqs l \big)
	} 
\geqs
\\
\geqs
	\frac{
		\PRob\big(E(H_p) \geqs l \big) 
			-
		\PRob\big(H_p \in A \big)
	}{
		\PRob\big(E(H_p) \geqs l\big)
	}
>
	1
		-
	\frac{\eps}{
		1 - \exp\left(-\frac{\delta^2}{2}pnN\right)
	},
\end{aligned}\end{equation}
После этого остаётся доказать, что $\PRob(G_l \not\in A) \geqs \PRob\Big( H_p \not\in A \big| E(H_p) \geqs l \Big)$.
Это делается аналогично предыдущему случаю, только на сей раз мы не добавляем рёбра, а равномерно выкидываем.
\end{proof}

\bigskip

Только что доказанная лемма позволяет нам оценивать $\PRob\big(Q(G_m) \geqs qn\big)$ через $\PRob\big(Q(H_p) \geqs q n\big)$.
Ясно, что рассматривать $q \geqs p$ не очень интересно, т.к. ребер в графе $H_p$ в среднем $pnN$, 
а значит, самое лучшее, на что мы можем рассчитывать, что каждый фрагмент скачан $pn$ клиентами.

Итак, $q < p$. Рассмотрим вероятность того, что первый фрагмент скачали хотя бы $qn$ клиентов, 
т.е. $\PRob\left(\sum\limits_{i=1}^n I_{i,1} \geqs qn\right)$. Пусть $\delta = 1 - \frac{q}{p}$, тогда:
\begin{align*}
\PRob\left(\sum_{i=1}^n I_{i,1} \geqs qn\right) = \PRob\left(\sum_{i=1}^n I_{i,1} \geqs (1 - \delta) pn\right) 
= 1 - \PRob\left(\sum_{i=1}^n I_{i,1} < (1 - \delta) pn\right),
\end{align*}
применяя теорему Чернова получаем:
\begin{align}
&\PRob\left(\sum_{i=1}^n I_{i,1} < (1 - \delta) pn\right) < \exp\left(- \frac{pn \delta^2}{2} \right)
\\
&\PRob\left(\sum_{i=1}^n I_{i,1} \geqs qn\right) > 1 - \exp\left(- \frac{pn \delta^2}{2} \right)
\end{align}

Теперь посмотрим, что мы знаем, про вероятность того, что все фрагменты скачены хотя бы $qn$ клиентами.
Заметим, что $I_{i,j}$ независимы, а значит и то, что происходит с первым фрагментом не зависит от того, 
что происходит с остальными фрагментами. Пользуясь этим получим:
\begin{equation}\label{mod1_pr}\begin{aligned}
&\PRob\big(Q(H_p) \geqs q n\big) = \left( \PRob\left(\sum_{i=1}^n I_{i,1} \leqs qn\right)  \right)^N >
\\
&\left( 1 - \exp\left(- \frac{pn \delta^2}{2} \right) \right)^N > 1 - N \cdot \exp\left(- \frac{pn \delta^2}{2} \right) 
\end{aligned}\end{equation}
где $\delta = 1 - \frac{q}{p}$. Всё вышесказанное позволит нам доказать следующую теорему:

%теорема 1
\begin{theorem}\label{t1}
Для любых $q$ и $\sigma$ таких, что $q, \sigma \in (0,1)$ верно
\begin{equation}
\PRob\big(Q(G_{\min(nN, \lceil pnN + 2\sqrt{pnN} \rceil)}) \geqs qn\big) > 1 - \sigma
\end{equation}
где $p \geqs q + c + \sqrt{c^2+2qc}, c = \frac{\ln(2N) - \ln(\sigma)}{n}$.
\end{theorem}
\begin{proof}
Для начала заметим, что если получится, что $pnN + 2\sqrt{pnN} \geqs nN$ то утверждение очевидно, 
поэтому далее мы будем считать, что $pnN + 2\sqrt{pnN} < nN$.

Сначала мы докажем, что 
\begin{equation}\label{t1_1}
\PRob\big(Q(H_p) \geqs qn \big) > 1 - \frac\sigma{2}.
\end{equation}
Из неравенства (\ref{mod1_pr}) мы знаем, что 
\begin{equation} \label{t1_t3_1}
\PRob\big(Q(H_p) \geqs qn \big) > 1 - N \cdot \exp\left(- \frac{n (p-q)^2}{2p} \right)
\end{equation}
Заметим, что $(p-q)^2 - 2pc = p^2 -2(q + c)p + q^2 \geqs 0$, а значит:
\begin{equation}
1 - N \cdot \exp\left(- \frac{n (p-q)^2}{2p} \right) = 1 - N \cdot \exp(-nc) = 1 - \frac\sigma{2}
\end{equation}
Тем самым мы доказали неравенство (\ref{t1_1}).
Осталось воспользоваться леммой \ref{l1}, а если точнее, то неравенством (\ref{l1_1}), взяв $\delta = \frac{2}{\sqrt{pnN}}$
 и $\eps = \frac\sigma{2}$, а множество $A$ -- все графы, для которых $Q(G) \geqs qn$.
Заметим, что $pnN > 2cnN> 2N\ln(2N) > 4$, а значит $\delta \in (0,1)$. Осталось заметить, что 
\begin{equation}
1 - \exp\left(-\frac{\delta^2}{4}pnN\right) = 1 - \frac{1}{e} > \frac{1}{2},
\end{equation}
что и завершает доказательство.
\end{proof}

\bigskip

Только что доказанная теорема позволяет находить необходимое количество проведённых ребер, чтобы выполнялось $Q(G_m) > qn$.
Попробуем привести оценку в другую сторону -- т.е. понять, какого количества точно не хватит.

Вернёмся к графу $H_p$, где $p \in [0,1]$ и вспомним, что ребро от $k$-го клиента к $K$-му фрагменту проводится тогда и только тогда
когда $I_{k,K} = 1$, где $I_{k,K}$ -- независимые бернуллиевские случайные величины с показателем $p$. 
Посчитаем вероятность того, что первый фрагмент скачали как минимум $qn$ клиентов:
\begin{equation}
\PRob\left(\sum_{i=1}^n I_{i,1} > qn\right) 
	= 
1 - \PRob\left(\sum_{i=1}^n I_{i,1} \leqs \lfloor qn \rfloor\right) 
	= 
1 - \PRob\big(Bin(n, p) \leqs l\big),
\end{equation}
где $l = \lfloor qn \rfloor$. Заметим, что для биномиального распределения мы знаем функцию распределения, 
а именно $\PRob\big(Bin(n, p) \leqs l\big) = I_{1-p}(n-l, l+1)$, где $I_x(a,b)$ -- регуляризованная неполная бета-функция:
\begin{equation}
I_x(a,b) = \frac{B_x(a,b)}{B(a,b)},
\end{equation}
для которой верно, что $I_x(a,b) = 1 - I_{1-x}(b, a)$.

Вспомнив, что $I_{k,K}$ -- независимые, посчитаем
\begin{equation}\label{n21}
\PRob(Q(H_p) > qn) = \big(1 - I_{1-p}(n-l, l+1)\big)^N = \big(I_{p}(l+1, n-l)\big)^n
\end{equation}
Теперь всё готово, для того, чтобы доказать аналог теоремы \ref{t1}.

% теорема 2
\begin{theorem}\label{t2}
Для любых $q$ и $\sigma$ таких, что $q, \sigma \in (0,1)$ верно
\begin{equation}
\PRob\big(Q(G_{\max(0, \lfloor pnN - \sqrt{2pnN} \rfloor)}) > qn\big) < \sigma
\end{equation}
где $p = \max\big(p :  I_p(l+1, n-l) \leqs \sqrt[n]{\frac\sigma{2}} \big)$.
\end{theorem}

\begin{proof}
Аналогично предыдущей теореме, предполагаем, что $pnN - \sqrt{2pnN} > 0$.
Заметим, что $I_x(a,b)$ -- монотонная по $x$ функция, а значит $I_p(l+1, n-l)^n \leqs \frac\sigma{2}$. 
Из неравенства (\ref{n21}) получаем, что
\begin{equation}
\PRob(Q(H_p) > qn) \leqs \frac\sigma{2}.
\end{equation}

Теперь воспользуемся леммой \ref{l1}, на сей раз неравенством (\ref{l1_2}).
Возьмём в качестве $A$ множество всех графов, для которых $Q(G) > qn$.
Также возьмём $\eps = \frac\sigma{2}$, $\delta = \sqrt{\frac{2}{pnN}}$.
Предположение $pnN - \sqrt{2pnN} > 0$ означает, что $\delta < 1$.
Заметим, что $1 - \exp\left(-\frac{\delta^2}{2}pnN\right) = 1 - \frac{1}{e} > \frac{1}{2}$, откуда получим, что
\begin{equation}
\PRob\big(G_{\lfloor pnN - \sqrt{2pnN} \rfloor} \in A\big) 
	< 
\frac{\frac\sigma{2}}{1 - \exp\left(-\frac{\delta^2}{2}pnN\right)}
	<
\sigma
\end{equation}
\end{proof}

% модель 2
\section{Модель 2. Выбор степеней клиентов.}
В этой моделе $G_m$ будет устроен немного другим образом. На сей раз, за каждый шаг мы будем равномерно выбирать клиента, 
у которого степень ещё не максимальная, а затем проводить ещё не проведённое ребро от выбранного клиента равномерным образом.
Заметим, что $E(G_m) = m$. Как и в прошлой моделе $G_m$ не очень удобен для исследования, поэтому мы построим граф $H_p$, где $p \in [0,1]$.

Граф $H_p$ строится так: выбираем $J_1, J_2, \dots, J_n$ --- пуассоновские случайные величины с показателем $\lambda = pN$.
$\min(J_k, N)$ --- степень $k$ - го клиента. После того, как все степени клиентов выбраны, 
выбираем нужное количество рёбер равномерным образом. Обозначим $J = \sum\limits_{k=1}^n J_k$. Заметим, что $E(H_p) \leqs J$.

%лемма 2
\begin{lemma} \label{l2}
Возьмём граф $H_p$ при условии того, что $J = m$. 
После этого добавим несколько рёбер тем же способом, который использовался при построении графа $G_m$. 
Добавлять будем до тех пор, пока в графе не окажется ровно $m$ ребер. 
Тогда полученный граф по распределению будет совпадать с графом $G_m$.
\end{lemma}
\begin{proof}
Для начала заметим, что мы можем следить только за распределением степеней клиентов, 
поскольку ребра из них во всех случаях проводятся равномерно. В частности когда мы строили $G_m$, 
мы могли сначала выбрать все степени клиентов, и только после этого начать проводить рёбра.

Заметим, что мы знаем, что $J_1, J_2, \dots, J_n$ при условии $J = m$ имеет мультиномиальное распределение 
$Multinom(m, p_i=\frac{1}{n}) = (Z_1, Z_2, \dots, Z_n)$. Значит, распределение степеней графа $H_p$ при условии $J = m$ такое же,
как у вектора $Z_{\min} = (\min(Z_1, N), \min(Z_2, N), \dots, \min(Z_n, N))$.
Попробуем описать словами этот случайный вектор.

Пусть у нас есть $n$ коробок. Мы берём $m$ шариков, и начинаем равномерно кидать их по коробкам. 
После этого во всех коробках, в которых оказалось больше $N$ шариков, лишние выкидываются.
Распределение количеств шариков в коробках как раз будет $Z_{\min}$. 

Вернемся к тому, как мы модифицируем граф $H_p$. Мы начинаем с вектора $Z_{\min}$ и начинаем докидывать шарики в коробки, 
равномерно по тем коробкам, в которых меньше $N$ шариков. Останавливаемся мы тогда, когда всего шариков будет ровно $m$ штук.

Заметим, что это то же самое, если с самого начала загадать число $m$, кидать шарики в коробки равномерно, 
но при этом, если в коробке, в которую мы кидаем шарик, уже $N$ шариков, то шарик пропадает. 
Останавливаемся мы в тот момент, когда в коробках будет ровно $m$ шариков. 
Нетрудно понять, что то же самое происходит и с распределением степеней графа $G_m$.
\end{proof}

\begin{cons} \label{cons_1}
Условие $J = m$ в лемме можно заменить на $J \leqs m$.
\end{cons}
\begin{proof}
Очевидно из доказательства леммы.
\end{proof}

\begin{proof}[Отступление]
Вернёмся к графу $H_p$ и посмотрим как часто происходит следующее событие: $\PRob(\exists k : J_k \geqs N)$.
Обозначим за $s(p, N) = \PRob(X \geqs N)$, где $X$ -- пуассоновская случайная величина с показателем $pN$.
Иногда аргументы мы будем опускать и писать просто $s$.
Заметим, что $\PRob(\exists k : J_k \geqs N) \leqs N \cdot s(p, N)$. 
Теперь воспользуемся неравенством (\ref{gr_1}) и получим следующие неравенства:
\begin{align}\label{ot_1}
&s(p,N) = \PRob(X \geqs N) \leqs \frac{e^{-pN}(e\cdot pN)^N}{N^N} = (e^{1-p} p )^N 
\\ \label{s_1}
&\PRob(\exists k : J_k \geqs N) \leqs N \cdot s(p, N) = N \cdot (e^{1-p} p )^N.
\end{align} 
Предположим, что $p \in [0, \frac{1}{2}]$, тогда $e^{1-p} p \leqs \frac{\sqrt{e}}{2}$, 
поскольку $(e^{1-p} p)'_p = (1-p) e^{1-p} > 0$. Поскольку $N \geqs 100$, то мы получаем, что 
\begin{equation}
s \leqs \left(\frac{\sqrt{e}}{2}\right)^N \leqs \frac{e^{50}}{2^{100}} < 10^{-8}.
\end{equation}
Аналогичным образом получаем, что 
\begin{equation}
\PRob(\exists k : J_k \geqs N) \leqs N \cdot \left(\frac{\sqrt{e}}{2}\right)^N
\leqs 100 \cdot \left(\frac{\sqrt{e}}{2}\right)^{100} < 10^{-6}.
\end{equation}
Тем самым мы поняли, что если $p \in [0, \frac{1}{2}]$, то $s$ и $\PRob(\exists k : J_k \geqs N)$ достаточно маленькие.
\end{proof}

Теперь вернёмся к графу $H_p$ и докажем лемму, аналогичную лемме \ref{l1}.

%лемма 3
\begin{lemma} \label{l3}
Пусть $A$ - множество всех графов, который обладают некоторым монотонным свойством, а $\delta \in (0,1)$.
Тогда, если $\PRob( H_p \in A) \geqs 1 - \eps$, то
\begin{equation} \label{l3_1}
\PRob(G_{\lceil pnN(1+\delta) \rceil} \in A) > 1 - \frac{\eps}{1 - \exp\left(-\frac{\delta^2}{4}pnN\right)};
\end{equation}
a если $\PRob( H_p \in A) \leqs \eps$, то
\begin{equation}\label{l3_2}
\PRob(G_{\lfloor pnN(1-\delta) \rfloor} \in A) < \frac{\eps}{1 - Ns - \exp\left(-\frac{\delta^2}{4}pnN\right)};
\end{equation}
\end{lemma}

\begin{proof}
Доказательство полностью аналогично доказательству леммы \ref{l1}, надо только применять следствие \ref{cons_1} из леммы \ref{l2}
и доказать следующие неравенства, 
аналогичные неравенствам (\ref{l1_3} - \ref{l1_4}) и (\ref{l1_5}) леммы \ref{l1}:
\begin{align} \label{l3_3}
\PRob\big( E(H_p) \leqs m \big) &> 1 - \exp\left(-\frac{\delta^2}{4}pnN\right)
\\ \label{l3_4}
\PRob\big( E(H_p) \geqs l \big) &> 1 - Ns - \exp\left(-\frac{\delta^2}{4}pnN\right),
\end{align}
где $m = \lceil pnN(1+\delta) \rceil$ a  $l = \lfloor pnN(1-\delta) \rfloor$.

Докажем неравенство (\ref{l3_3}). Вспомним, что $E(H_p) \leqs J$, где $J = \sum\limits_{k = 1}^n J_k$. Заметим, что
\begin{equation}\label{l3_5}\begin{aligned}
\PRob\big( E(H_p) \leqs m \big) > \PRob\big( J < m \big) \geqs \PRob\big( J < pnN(1+\delta) \big) 
=
\\
= 
1 - \PRob\big( J \geqs pnN(1+\delta) \big) \geqs 1 - \frac{e^{-pnN}(epnN)^{pnN(1+\delta)}}{(pnN(1+\delta))^{pnN(1+\delta)}}
=
\\
=
1 - \left( \frac{e^{-1} e^{1+\delta}(pnN)^{1+\delta}}{(pnN)^{1+\delta}(1+\delta)^{1+\delta}} \right)^{pnN}
=
1 - \left( \frac{e^\delta}{(1+\delta)^{1+\delta}} \right)^{pnN}
\end{aligned}\end{equation}
где в последнем неравенстве было замечено, что $J$ --- пуассоновская случайная величина с показателем $pnN$, 
и было применяно неравенство (\ref{gr_1}).
Теперь заметим, что 
\begin{equation}\begin{aligned}
&\PRob\big( E(H_p) \leqs m \big) > 1 - \left( \frac{e^\delta}{(1+\delta)^{1+\delta}} \right)^{pnN}
=
\\
=
&1 - \exp\big(pnN \cdot (\delta - (1+\delta) \ln(1+\delta)) \big)
\geqs
 1 - \exp\left(-\frac{\delta^2}{4}pnN\right),
\end{aligned}\end{equation}
где мы применили неравенство $\delta - (1+\delta) \ln(1+\delta) \leqs - \frac{\delta^2}{4}$, 
которое верно для $\delta \in (0,1)$. Тем самым неравенство (\ref{l3_3}) доказано.

Теперь докажем неравенство (\ref{l3_4}). Пусть $A$ -- событие $\{\exists k : J_k \geqs N\}$.
Вспомним, что $\PRob(A) \leqs Ns$, что сказано в неравенстве (\ref{s_1}). Заметим, что
\begin{equation}\begin{aligned}
\PRob\big( E(H_p) &\geqs l \big) = 
	\PRob\big(E(H_p) \geqs l | A\big) \cdot \PRob(A) + \PRob\big(E(H_p) \geqs l | \overline{A}\big) \cdot \PRob(\overline{A})
\geqs
\\
\geqs
&\PRob\big(J \geqs l | \overline{A}\big) \cdot \PRob(\overline{A})
	=
\PRob\big(J \geqs l \cap \overline{A} \big) 
	\geqs
\PRob\big(J \geqs l \big) - \PRob(A),
\end{aligned}\end{equation}
поскольку при условии $\overline{A}$, $E(H_p) = J$. Продолжим оценивать:
\begin{equation}\begin{aligned}
\PRob\big( E(H_p) \geqs l \big) 
	\geqs 
\PRob\big(J \geqs l \big) - \PRob(A) 
	>
\PRob\big(J > l \big) - Ns
	\geqs
\\
	\geqs
\PRob\big(J > pnN(1-\delta) \big) - Ns
	=
1 - Ns - \PRob\big( J \leqs pnN(1-\delta)  \big).
\end{aligned}\end{equation}
Теперь аналогично (\ref{l3_5}) используя неравенство (\ref{gr_2}) получаем:
\begin{equation}\begin{aligned}
\PRob\big( J \leqs pnN(1-\delta) \big) 
	\leqs
\frac{
	e^{-pnN}(epnN)^{pnN(1-\delta)}
}{
	(pnN(1-\delta))^{pnN(1-\delta)}
}
	=
\left( \frac{e^{-\delta}}{(1-\delta)^{(1-\delta)}} \right)^{pnN}
	=
\\
	=
\exp\big(pnN \cdot (-\delta - (1-\delta)\ln(1-\delta)) \big)
	<
\exp\left(-\frac{\delta^2}{4}pnN\right),
\end{aligned}\end{equation}
где в последнем переходе использовалось неравенство $-\delta - (1-\delta)\ln(1-\delta) < - \frac{\delta^2}{4}$, 
которое верно при $\delta \in (0,1)$. Неравенство (\ref{l3_4}) доказано, а значит и лемма тоже.
\end{proof}

Итак, нас как и в прошлый раз будет интересовать $\PRob(Q(H_p) \geqs qn)$, где $q$ некоторое число, меньшее $p$.
Более того, предположим, что $q < p - s$.

Введём случайные величины $T_1, T_2, \dots, T_N$, заданные так: $T_i = 1$ если $i$-й фрагмент скачали хотя бы $qn$ клиентов, 
в противном случае $T_i = 0$. Заметим, что $\PRob(Q(H_p) \geqs qn) = \PRob\big(\sum\limits_{i=1}^N T_i = N\big)$.

Посчитаем $\PRob(T_i = 1)$. Ясно, что эта вероятность не зависят от выбора $i$, а значит, 
не умоляя общности, мы можем посчитать только $\PRob(T_1 = 1)$.
Пусть $I_1, I_2, \dots, I_n$ бернулевские случайные величины, такие, что $I_i = 1$ тогда и только тогда, 
когда $i$ клиент скачал первый фрагмент. 

Посчитаем $\PRob(I_i = 1) = \PRob(I_1 = 1)$ следующем образом:
\begin{equation}\begin{aligned}
&\PRob(I_1 = 1) = \sum_{i = 0}^\infty \PRob(J_1 = i) \cdot \PRob(I_1 = 1 | J_1 = i) 
	= 
\\
	= 
&\sum_{i = 0}^N e^{-\lambda} \frac{\lambda^k}{k!} \cdot \frac {k}{N} + \PRob(J_1 > N)
	=
\sum_{i = 0}^{\infty} e^{-\lambda} \frac{\lambda^k}{k!} \cdot \frac {k}{N}  
	- 
	\\
	-
&\sum_{i = N + 1}^{\infty} e^{-\lambda} \frac{\lambda^k}{k!} \cdot \left(\frac {k}{N} - 1\right)
	=
\frac{\lambda}{N} - \frac{\lambda}{N} \cdot s + s - e^{-\lambda} \frac{\lambda^N}{N!},
\end{aligned}\end{equation}
где $\lambda = pN$. Из неравенств выше видно, что $r = \PRob(I_1 = 1) \in (p - s, p)$.

Вернёмся к подсчёту $\PRob(T_1 = 1)$:
\begin{equation}\begin{aligned}
\PRob(T_1 = 1) = \PRob\left(\sum_{i=1}^n I_i \geqs qn\right) 
	= 
1 - \PRob\left(\sum_{i=1}^n I_i < (1-\delta)n\right)
	>
\\
	>
1 - \exp \left( - \frac{rn \delta^2}{2} \right),
\end{aligned}\end{equation}
где $\delta = 1 - \frac{q}{r}$, и мы в очередной раз применили теорему Чернова. 
Заметим, что $\delta > 0$, т.к. мы предположили, что $q < p-s < r$.
Пусть $T = \sum\limits_{i = 0}^n T_i$. Заметим, что 
\begin{equation}
\Expect T \leqs N \PRob(T = N) + (N-1) (1 - \PRob(T = N)) = N + \PRob(T = N) - 1,
\end{equation}
откуда получим следующее:
\begin{equation}\begin{aligned}
\PRob(T = N) \geqs \Expect T + 1 - N > N \cdot \left(1 - \exp \left( - \frac{rn \delta^2}{2} \right)\right)  + 1 - N
=
	\\
=
1 - N \cdot \exp \left( - \frac{rn \delta^2}{2} \right).
\end{aligned}\end{equation}
Запишем итоговое неравенство:
\begin{equation}\label{t3_1} \begin{aligned}
\PRob\big(Q(H_p) \geqs qn \big) 
	> 
1 - N \cdot \exp\left(- \frac{n (r-q)^2}{2r} \right)
	>
\\ 
	>  
1 - N \cdot \exp\left(- \frac{n (p - q - s)^2}{2p} \right) 
\end{aligned}\end{equation}

Теперь всё готово для теоремы, аналогичной теореме \ref{t1}.

%теорема 3
\begin{theorem}\label{t3}
Для любых $q$ и $\sigma$ таких, что $q, \sigma \in (0,1)$ верно
\begin{equation}
\PRob\big(Q(G_{\min(nN, \lceil pnN + 2\sqrt{pnN} \rceil)}) \geqs qn\big) > 1 - \sigma
\end{equation}
где $p$ такое, что 
\begin{equation}\label{t3_2}
p \geqs q + s(p, N) + c + \sqrt{c^2+2(q+s(p, N))c}
\end{equation}
a $c = \frac{\ln(2N) - \ln(\sigma)}{n}$.
\end{theorem}
\begin{proof}
Доказательство дословно переносится с доказательства теоремы \ref{t1}, 
где в качестве неравенства (\ref{t1_t3_1}) выступает неравенство (\ref{t3_1}). 
Также, вместо леммы \ref{l1} и неравенства (\ref{l1_1}) выступает лемма \ref{l3} и неравенство (\ref{l3_1}).
\end{proof}

В только что доказанной теоремы есть небольшой изъян -- на $p$ наложено достаточно сложное условие. 
Постараемся его немного упростить.
\begin{cons}
Пусть $(q+c) < \frac{1}{4}$, тогда условие на $p$ можно заменить на следующее:
\begin{equation}
p = 2\left(q + c + \exp\left(-\frac{N}{18}\right) \right)
\end{equation}

\begin{proof}
Покажем, что для такого $p$ выполняется условие (\ref{t3_2}).
Заметим, что $p < \frac{1}{2} + \frac{2}{e^5} < \frac{2}{3}$, поскольку $N > 100$.
Также вспомним неравенство (\ref{ot_1}) и улучшим его:
\begin{equation}
s(p, N) \leqs (e^{1-p} p)^N 
	=
\exp\big(N( ln(p) + (1-p) )\big)
	\leqs
\exp\left( - N \cdot \frac{(1-p)^2}{2}\right),
\end{equation}
где мы применили неравенство $ln(p) + (1-p) \leqs - \frac{(1-p)^2}{2}$, которое верно для $p\in(0,1)$.
Теперь заметим, что, поскольку $p < \frac{2}{3}$, то 
\begin{equation}
\exp\left( - N \cdot \frac{(1-p)^2}{2}\right) < \exp\left( - N\cdot \frac{1}{18}\right),
\end{equation}
откуда мы получаем, что 
\begin{equation}
p > 2(q+c+s(p,N)) \geqs q + s(p, N) + c + \sqrt{c^2+2(q+s(p, N))c}
\end{equation}
\end{proof}
\end{cons}



\section{Модель 3. Выбор редкого фрагмента}

В этой модели $G_m$ будет строиться так: сначала выбираем случайного клиента, а затем выбираем наиболее редкий фрагмент и скачиваем его.
Если же таковых несколько, то можно либо выбирать любой из них, либо с минимальным индексом. 
На дальнейшие рассуждения это влиять не будет.

%лемма 4
\begin{lemma}\label{l4}
Пусть $m \leqs \frac{nN}{5}$ и $\delta < 2e - 1$, тогда вероятность того, что в графе $G_m$ существует клиент, 
со степенью большей чем $(1+\delta)\frac{N}{5}$ меньше, чем $n \exp\left(- \frac{\delta^2 N}{20}\right)$.
\end{lemma}
\begin{proof}
Заметим, что от того, что мы возьмём $m$ побольше, эта вероятность только увеличится. 
А значат, мы имеем право рассуждать только про $m = \frac{nN}{5}$. 
Пусть $T_1, T_2, \dots, T_m$ -- случайные величины, такие, что $T_i = 1$ тогда и только тогда, 
когда мы на $i$-том шагу выбрали $1$-го клиента.
Заметим, что 
\begin{equation}
\PRob\left(\sum_{i = 1}^m T_i > (1+\delta)\frac{m}{n} \right) < \exp\left(- \frac{\delta^2 N}{20} \right),
\end{equation}
поскольку $T_i$ -- независимые бернуллиевские случайные величины с показателем $\frac{1}{n}$, и мы применили к ним теорему Чернова.
Тем самым мы оценили вероятность того, что первый клиент имеет стемень большую, чем $(1+\delta)\frac{nN}{5}$.
Ясно, что искомая вероятность не более чем в $n$ раз больше.
\end{proof}

Итак, мы по прежнему будем следить за функцией $Q(G_m)$. Для этого введём ещё одну функцию $W(G_m)$, 
которая будет выдавать максимальную степень фрагмента.
Кроме того, введем $R(m) = W(G_m) - Q(G_m)$. 
Ясно, что $R(m+1) - R(m)$ может быть только $\{-1,0,1\}$, поскольку мы добавили всего одно ребро в граф, 
а значит изменили степень только одного фрагмента и то на $1$. 

\begin{theorem}
Пусть $m \leqs \frac{nN}{5}$, тогда
\begin{equation}
\PRob\left(\exists l \leqs m : R(l) > 2 \right) < n\exp\left(-\frac{N}{5}\right) +  \exp\left(- \frac{N}{20}\right)
\end{equation}

\begin{proof}
Разыграем растущий граф: $G_1, G_2, \dots G_m$. Пусть для этого растущего графа нашлось такое $l \leqs m$, что $ R(l) > 2$.
Обозначим за $m_2$ минимальное такое $l$. Заметим, что $R(m_2 - 1) = 2$. 
Теперь обозначим за $m_1$ максимальное $l$ такое, что $l < m_2$ и $R(l-1) = 1$.
Таким образом, $R(m_2) = 3, R(m_1 - 1) = 1$, и $R(l) = 2$ для любого $l \in [m1, m2)$.

Пусть $D = 3 \cdot \frac{N}{5}$. Пусть степени всех клиентов графа $G_m$ не более, чем $D$. 
Заметим, что вероятность этого хотя бы $1 -  n\exp\left(-\frac{N 2^2}{20}\right)$ по лемме \ref{l4}.
Также заметим, что степени всех клиентов графов $G_1, G_2, \dots G_m$ не превосходят $D$.

Давайте ещё немного поисследуем ситуацию, которую мы имеем. Например мы знаем, что в момент $m_1$ есть 
только один фрагмент с максимальной степенью. Обозначим эту степень за $L + 1$, тогда минимальная степень будет $L - 1$.
Также заметим, что до момента $m_2$ других степеней не будет, т.к. минимум и максимум не могли меняться, т.к. иначе бы 
наблюдалось изменение $R(l)$. 

Заметим, что в момент $m_1 - 1$ 
количество фрагментов степени $L$ было хотя бы $N-D$, т.к. чтобы сотворить фрагмент степени $L+1$ необходимо, 
чтобы все нескаченные фрагменты выбранным клиентом были бы степени $L$ или большей (но больших степеней точно нет), а вот минимальная антистепень 
клиента точно хотя бы $N - D$. Аналогичные рассуждения верны для момента $m_2 - 1$, т.е. в этот момент должно быть хотя бы $N - D$
вершин степени $L+1$. 

Я утверждаю, что в момент $\min(m_1 - 1 + N, m_2 - 1)$ будет хотя бы $N-D$ фрагментов степени $L+1$.
Пусть $m_1 - 1 + N < m_2 - 1$, иначе мы это уже выяснили.
Заметим, что в момент $m_2 - 1$ фрагментов степени $L$ хотя бы $N-D$, а значит,
фрагментов степени $L - 1$ не более $D$. Далее, за каждый шаг $(m_1 - 1) \to (m_1)$, $(m_1) \to (m_1 + 1)$, \dots, 
$(m_1 - 2 + N) \to (m_1 - 1 + N)$
 мы либо увеличиваем количество фрагментов степени $L+1$, либо уменьшаем количество фрагментов степени $L-1$.
Поскольку фрагменты степени $L-1$ не пропали, значит мы как минимум $N-D + 1$ раз увеличили количество фрагментов $L+1$, 
т.е. в момент $m_1 - 1 + N$ таких фрагментов будет больше, чем $N - D$.

Разберёмся теперь, каким образом увеличивается количество фрагментов степени $L+1$. 
Ясно, что чтобы такое произошло, необходимо выбрать клиента, который бы скачал все фрагменты степени $L-1$. 
Не вызывает сомнений, что таких клиентов не может быть больше, чем $L-1$, поскольку они все скачали какой-то фрагмент степени $L-1$.
Итак, давайте на каждом шагу нумеровать клиентов так: первые номера получат те клиенты, 
которые скачали все фрагменты степени $L-1$, остальные клиенты получают последующие номера. 
Заметим, что для того, чтобы за $\min(N, m_2 - m_1)$ шагов как минимум $N-D$ раз увеличить количество фрагментов степени $L+1$,
необходимо как минимум $N-D$ раз выбрать клиента с номером не более, чем $L-1$.

Тем самым, вероятность того, что в момент $\min(m_1 - 1 + N, m_2 - 1)$ будет хотя бы $N-D$ фрагментов степени $L+1$, 
не более, чем $ A = \PRob(I_1 + I_2 + \dots + I_{\min(N, m_2 - m_1)} > N - D)$, 
где $I_k$ -- независимые бернуллиевские случайные величины с показателем $\frac{L-1}{n}$.

Вспомним, что всё это происходило при допущении, что степени всех клиентов не более $D$, 
а значит, $\PRob\left(\exists l \leqs m : R(l) > 2 \right) < A +  n\exp\left(-\frac{N}{5}\right)$, 
поскольку либо должен будет найтись клиент с большой степенью, 
либо к моменту $\min(m_1 - 1 + N, m_2 - 1)$ должно будет найтись много фрагментов степени $L+1$.

Осталось доказать, что 
\begin{equation}
A < \exp\left(- \frac{n}{8}\right).
\end{equation}
Заметим, что $(L-1) N < m_1 < \frac{nN}{5}$, т.к. $L-1$ -- минимальная степень фрагмента в момент $m_1$.
Значит, $\frac{L-1}{n} < \frac{1}{5}$. Заметим, что
\begin{equation}
A \leqs \PRob\left(\sum_{k = 1}^N I_k > N - D\right) \leqs \PRob\left(\sum_{k = 1}^N J_k > N - D\right),
\end{equation}
где $J_k$ -- независимые бернуллиевские случайные величины с показателем $\frac{1}{5}$. 
Заметим, что $N - D = 2 \frac{N}{5}$, а значит мы можем применить 
теорему Чернова для $\sum\limits_{k = 1}^N J_k$ и получить
\begin{equation}
\PRob\left(\sum_{k = 1}^N J_k > (1 + 1) \frac{N}{5}\right) < \exp\left( - \frac{N}{20}\right)
\end{equation}

\end{proof}

\end{theorem}




\end{document}
