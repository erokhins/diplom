\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}
\inputencoding{utf8}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amssymb}

\newcommand{\Expect}{\mathbb E}
\newcommand{\PRob}{\mathbb P}
\newcommand{\leqs}{\leqslant}
\newcommand{\geqs}{\geqslant}
\newcommand{\eps}{\varepsilon}

\newtheorem{theorem}{Теорема}
\newtheorem{note}{Замечание}
\newtheorem{cons}{Следствие}
\newtheorem{define}{Определение}
\newtheorem{lemma}{Лемма}

\newtheoremstyle{named}{}{}{\itshape}{}{\bfseries}{.}{.5em}{#1 #3}
\theoremstyle{named}
\newtheorem*{namedtheorem}{Теорема}
\newtheorem*{namedpropo}{}

\begin{document}
\section{Основные определения}
В рамках этой дипломной работы мы будем иметь дело только с двудольными графами доли которых мы условно назовём клиенты и фрагменты.
Ребро между некоторым клиентом и фрагментом будет означать, что данный клиент скачал данный фрагмент.
Обозначим количество клиентов за $n$, а количество фрагментов за $N$. В рамках данной работы, будем предполагать, что $n, N \geqs 100$.
Заметим, что максимальное возможное количество рёбер в таком графе $nN$.

Пусть дан произвольный двудольный граф $G$. Определим для него несколько функций:
\begin{align*}
&E(G) \text{ --- количество рёбер}\\
&Q(G) \text{ --- минимальная степень фрагмента}
\end{align*}
Нас будет интересовать, как ведёт себя функция $Q(G)$ при различных моделях роста графа $G$.

\begin{define}
Некоторое свойство графа будем называть монотонным, если оно сохраняется при добавлении рёбер.
\end{define}

\begin{note}
Пусть $k$ -- натуральное число. Тогда свойство $Q(G) > k$ является монотонным свойством.
\end{note}

Также сформулируем некоторые известные теоремы, которыми мы будем пользоваться.
\begin{namedtheorem}[Чернова] (Для бернуллиевских случайных величин) \label{Cher} 

Пусть у нас есть $X_1, X_2, X_3, \dots X_n$ -- 
независимые бернуллиевские случайные величины(не обязательно одинаково распределенные). Пусть $X = \sum\limits_{i = 1}^n X_i$ и
$\mu = \Expect X$, также пусть $\delta > 0$. Тогда выполняются следующие неравенства:

\begin{align}
\PRob[X < (1-\delta)\mu] &< \exp\left(- \frac{\mu \delta^2}{2} \right)
\\
\PRob[X > (1+\delta)\mu] &< \exp\left(- \frac{\mu \delta^2}{4} \right) \text{, при } \delta < 2e - 1
\end{align}
\end{namedtheorem}
Доказательство этой теоремы можно найти в статье \cite{chernov}.

\begin{namedpropo}[Граница Чернова] (Для пуассоновской случайной величины)

Пусть $X$ -- пуассоновская случайная величина с показателем $\lambda$, тогда верны следующие неравенства:
\begin{align} \label{gr_1}
\PRob(X \geqs x) \leqs \frac{e^{-\lambda}(e\lambda)^x}{x^x}, \text{ для всех } x > \lambda 
\\
\label{gr_2}
\PRob(X \leqs x) \leqs \frac{e^{-\lambda}(e\lambda)^x}{x^x}, \text{ для всех } x < \lambda 
\end{align}
\end{namedpropo}
Доказательство этого утверждения можно найти в \cite{chernov_gr}.

\section{Модель 1. Равномерный выбор рёбер.}
В этой модели граф будет расти следующим образом: на каждом шагу мы равномерно выбираем произвольное ещё не проведённое ребро 
и проводим его. Обозначим за $G_m$ граф, который получается на $m$-том шагу. Ясно, что $E(G_m) = m$.
Выберем некоторое число $q \in (0, 1)$ и зададимся вопросом, насколько велико должно быть $m$, чтобы выполнялось: $Q(G_m) > qn$.
К сожалению, исследовать граф $G_m$ напрямую не очень удобно, поэтому мы создадим некоторый граф, который будет похож на граф $G_m$.

Создадим граф $H_p$, где $p \in [0, 1]$, который будет построен по следующему правилу: 
разыгрываем $nN$ бернуллиевских случайных величин $I_{1,1}, I_{1,2}, \dots I_{n,N}$ с показателем $p$ и проводим ребро от $k$-го клиента к $K$ фрагменту, 
если $I_{k, K} = 1$.
Заметим, что случайный граф $G_m$ устроен следующим образом: все графы, в которых ровно $m$ рёбер, выпадают с одинаковой вероятностью.
А если взять граф $H_p$ при условии того, что $E(H_p) = m$, то тогда он устроен так же, как и $G_m$.
Это позволит нам доказать следующую лемму:

%лемма 1
\begin{lemma} \label{l1}
Пусть $A$ - множество всех графов, который обладают некоторым монотонным свойством, а $\delta \in (0,1)$.
Тогда, если $\PRob( H_p \in A) \geqs 1 - \eps$, то
\begin{equation} \label{l1_1}
\PRob(G_{\lceil pnN(1+\delta) \rceil} \in A) > 1 - \frac{\eps}{1 - \exp\left(-\frac{\delta^2}{4}pnN\right)};
\end{equation}
a если $\PRob( H_p \in A) \leqs \eps$, то
\begin{equation}\label{l1_2}
\PRob(G_{\lfloor pnN(1-\delta) \rfloor} \in A) < \frac{\eps}{1 - \exp\left(-\frac{\delta^2}{2}pnN\right)};
\end{equation}
\end{lemma}

\begin{proof}
Будем доказывать неравенство (\ref{l1_1}). Заметим, что 
\begin{equation}
E(H_p) = \sum_{k=1}^n \sum_{K=1}^N I_{k, K},
\end{equation}
где $I_{k,K}$ -- бернуллиевские случайные величины с показателем $p$.
Применим к $E(H_p)$ теорему Чернова, где $\mu = \Expect(E(H_p) = pnN$, а $\delta$ взята из условия леммы.
Получим следующее неравенство:
\begin{equation}\label{l1_3}
\PRob\big( E(H_p) \leqs pnN(1+\delta) \big) > 1 - \exp\left(-\frac{\delta^2}{4}pnN\right).
\end{equation}
Заметим, что $m = \lceil pnN(1+\delta) \rceil \geqs pnN(1+\delta)$, а значит
\begin{equation}\label{l1_4}
\PRob\big( E(H_p) \leqs m \big) \geqs \PRob\big( E(H_p) \leqs pnN(1+\delta) \big)
\end{equation}
Положим $B = \PRob\Big( H_p \in A \big| E(H_p) \leqs m \Big)$. Заметим, что
\begin{equation}\label{l1_big}
\begin{aligned}
B = \frac{
		\PRob\Big( H_p \in A \bigcap E(H_p) \leqs m \Big)
	}{
		\PRob\big(E(H_p) \leqs m \big)
	} 
&\geqs 
	\frac{
		\PRob\big(E(H_p) \leqs m \big) 
			-
		\PRob\big(H_p \not\in A \big)
	}{
		\PRob\big(E(H_p) \leqs m\big)
	}
=
\\
=
	1 
		-
	\frac{
		\PRob\big(H_p \not\in A \big)
	}{
		\PRob\big(E(H_p) \leqs m\big)
	}
&>
	1
		-
	\frac{\eps}{
		1 - \exp\left(-\frac{\delta^2}{4}pnN\right)
	},
\end{aligned}\end{equation}
где в последнем переходе мы воспользовались неравенствами (\ref{l1_3}), (\ref{l1_4}) 
и неравенством $\PRob\big(H_p \not\in A \big) < \eps$, которое очевидно из условия леммы.
Теперь докажем, что $\PRob(G_{\lceil pnN(1+\delta) \rceil} \in A) \geqs B$.

Рассмотрим граф $H_p$ при условии того, что $E(H_p) \leqs m$ и обозначим его $H_p^m$. 
Заметим, что этот граф удовлетворяет свойству $A$ с вероятностью $B$, а $E(H_p^m) \leqs m$.
Теперь мы несколько раз добавим ребер в этот граф, пока в нем не станет ровно $m$ ребер, 
при этом на каждом шагу ребра будем выбирать равномерно.
\\
Заметим, что мы получим случайный граф, в котором ровно $m$ ребер. Несложно понять, 
что этот граф по распределению совпадает с $G_m$, т.к. мы нигде не различали рёбра между собой, а значит они перестановочны.
При этом мы знаем, что граф $H_p^m$, с которого мы начинали, обладал свойством $A$ с вероятностью $B$, 
а значит $\PRob(G_m \in A) \geqs B$. Применяя неравенство (\ref{l1_big}) получаем (\ref{l1_1}).

Теперь докажем (\ref{l1_2}). Пусть $l = \lfloor pnN(1-\delta) \rfloor$. Аналогично неравенствам (\ref{l1_3}) и (\ref{l1_4}) получаем
\begin{equation} \label{l1_5}
\PRob\big( E(H_p) \geqs l \big) > 1 - \exp\left(-\frac{\delta^2}{2}pnN\right).
\end{equation}
После этого получаем аналог неравенства (\ref{l1_big})
\begin{equation}\label{l1_big2}
\begin{aligned}
	\PRob\Big( H_p \not\in A \big| E(H_p) \geqs l \Big)
=
	\frac{
		\PRob\Big( H_p \not\in A \bigcap E(H_p) \geqs l \Big)
	}{
		\PRob\big(E(H_p) \geqs l \big)
	} 
\geqs
\\
\geqs
	\frac{
		\PRob\big(E(H_p) \geqs l \big) 
			-
		\PRob\big(H_p \in A \big)
	}{
		\PRob\big(E(H_p) \geqs l\big)
	}
>
	1
		-
	\frac{\eps}{
		1 - \exp\left(-\frac{\delta^2}{2}pnN\right)
	},
\end{aligned}\end{equation}
После этого остаётся доказать, что $\PRob(G_l \not\in A) \geqs \PRob\Big( H_p \not\in A \big| E(H_p) \geqs l \Big)$.
Это делается аналогично предыдущему случаю, только на сей раз мы не добавляем рёбра, а равномерно выкидываем.
\end{proof}

\bigskip

Только что доказанная лемма позволяет нам оценивать $\PRob\big(Q(G_m) \geqs qn\big)$ через $\PRob\big(Q(H_p) \geqs q n\big)$.
Ясно, что рассматривать $q \geqs p$ не очень интересно, т.к. ребер в графе $H_p$ в среднем $pnN$, 
а значит, самое лучшее, на что мы можем рассчитывать, что каждый фрагмент скачан $pn$ клиентами.

Итак, $q < p$. Рассмотрим вероятность того, что первый фрагмент скачали хотя бы $qn$ клиентов, 
т.е. $\PRob\left(\sum\limits_{i=1}^n I_{i,1} \geqs qn\right)$. Пусть $\delta = 1 - \frac{q}{p}$, тогда:
\begin{align*}
\PRob\left(\sum_{i=1}^n I_{i,1} \geqs qn\right) = \PRob\left(\sum_{i=1}^n I_{i,1} \geqs (1 - \delta) pn\right) 
= 1 - \PRob\left(\sum_{i=1}^n I_{i,1} < (1 - \delta) pn\right),
\end{align*}
применяя теорему Чернова получаем:
\begin{align}
&\PRob\left(\sum_{i=1}^n I_{i,1} < (1 - \delta) pn\right) < \exp\left(- \frac{pn \delta^2}{2} \right)
\\
&\PRob\left(\sum_{i=1}^n I_{i,1} \geqs qn\right) > 1 - \exp\left(- \frac{pn \delta^2}{2} \right)
\end{align}

Теперь посмотрим, что мы знаем, про вероятность того, что все фрагменты скачены хотя бы $qn$ клиентами.
Заметим, что $I_{i,j}$ независимы, а значит и то, что происходит с первым фрагментом не зависит от того, 
что происходит с остальными фрагментами. Пользуясь этим получим:
\begin{equation}\label{mod1_pr}\begin{aligned}
&\PRob\big(Q(H_p) \geqs q n\big) = \left( \PRob\left(\sum_{i=1}^n I_{i,1} \leqs qn\right)  \right)^N >
\\
&\left( 1 - \exp\left(- \frac{pn \delta^2}{2} \right) \right)^N > 1 - N \cdot \exp\left(- \frac{pn \delta^2}{2} \right) 
\end{aligned}\end{equation}
где $\delta = 1 - \frac{q}{p}$. Всё вышесказанное позволит нам доказать следующую теорему:

%теорема 1
\begin{theorem}\label{t1}
Для любых $q$ и $\sigma$ таких, что $q, \sigma \in (0,1)$ верно
\begin{equation}
\PRob\big(Q(G_{\min(nN, \lceil pnN + 2\sqrt{pnN} \rceil)}) \geqs qn\big) > 1 - \sigma
\end{equation}
где $p = q + c + \sqrt{c^2+2qc}, c = \frac{\ln(2N) - \ln(\sigma)}{n}$.
\end{theorem}
\begin{proof}
Для начала заметим, что если получится, что $pnN + 2\sqrt{pnN} \geqs nN$ то утверждение очевидно, 
поэтому далее мы будем считать, что $pnN + 2\sqrt{pnN} < nN$.

Сначала мы докажем, что 
\begin{equation}\label{t1_1}
\PRob\big(Q(H_p) \geqs qn \big) > 1 - \frac\sigma{2}.
\end{equation}
Из неравенства (\ref{mod1_pr}) мы знаем, что 
\begin{equation}
\PRob\big(Q(H_p) \geqs qn \big) > 1 - N \cdot \exp\left(- \frac{n (p-q)^2}{2p} \right)
\end{equation}
Заметим, что $(p-q)^2 = 2c^2 + 2qc + 2c\sqrt{c^2 + 2qc} = 2pc$, а значит:
\begin{equation}
1 - N \cdot \exp\left(- \frac{n (p-q)^2}{2p} \right) = 1 - N \cdot \exp(-nc) = 1 - \frac\sigma{2}
\end{equation}
Тем самым мы доказали неравенство (\ref{t1_1}).
Осталось воспользоваться леммой \ref{l1}, а если точнее, то неравенством (\ref{l1_1}), взяв $\delta = \frac{2}{\sqrt{pnN}}$
 и $\eps = \frac\sigma{2}$, а множество $A$ -- все графы, для которых $Q(G) \geqs qn$.
Заметим, что $pnN > 2cnN> 2N\ln(2N) > 4$, а значит $\delta \in (0,1)$. Осталось заметить, что 
\begin{equation}
1 - \exp\left(-\frac{\delta^2}{4}pnN\right) = 1 - \frac{1}{e} > \frac{1}{2},
\end{equation}
что и завершает доказательство.
\end{proof}

\bigskip

Только что доказанная теорема позволяет находить необходимое количество проведённых ребер, чтобы выполнялось $Q(G_m) > qn$.
Попробуем привести оценку в другую сторону -- т.е. понять, какого количества точно не хватит.

Вернёмся к графу $H_p$, где $p \in [0,1]$ и вспомним, что ребро от $k$-го клиента к $K$-му фрагменту проводится тогда и только тогда
когда $I_{k,K} = 1$, где $I_{k,K}$ -- независимые бернуллиевские случайные величины с показателем $p$. 
Посчитаем вероятность того, что первый фрагмент скачали как минимум $qn$ клиентов:
\begin{equation}
\PRob\left(\sum_{i=1}^n I_{i,1} > qn\right) 
	= 
1 - \PRob\left(\sum_{i=1}^n I_{i,1} \leqs \lfloor qn \rfloor\right) 
	= 
1 - \PRob\big(Bin(n, p) \leqs l\big),
\end{equation}
где $l = \lfloor qn \rfloor$. Заметим, что для биномиального распределения мы знаем функцию распределения, 
а именно $\PRob\big(Bin(n, p) \leqs l\big) = I_{1-p}(n-l, l+1)$, где $I_x(a,b)$ -- регуляризованная неполная бета-функция:
\begin{equation}
I_x(a,b) = \frac{B_x(a,b)}{B(a,b)},
\end{equation}
для которой верно, что $I_x(a,b) = 1 - I_{1-x}(b, a)$.

Вспомнив, что $I_{k,K}$ -- независимые, посчитаем
\begin{equation}\label{n21}
\PRob(Q(H_p) > qn) = \big(1 - I_{1-p}(n-l, l+1)\big)^N = \big(I_{p}(l+1, n-l)\big)^n
\end{equation}
Теперь всё готово, для того, чтобы доказать аналог теоремы \ref{t1}.

% теорема 2
\begin{theorem}\label{t2}
Для любых $q$ и $\sigma$ таких, что $q, \sigma \in (0,1)$ верно
\begin{equation}
\PRob\big(Q(G_{\max(0, \lfloor pnN - \sqrt{2pnN} \rfloor)}) > qn\big) < \sigma
\end{equation}
где $p = \max\big(p :  I_p(l+1, n-l) \leqs \sqrt[n]{\frac\sigma{2}} \big)$.
\end{theorem}

\begin{proof}
Аналогично предыдущей теореме, предполагаем, что $pnN - \sqrt{2pnN} > 0$.
Заметим, что $I_x(a,b)$ -- монотонная по $x$ функция, а значит $I_p(l+1, n-l)^n \leqs \frac\sigma{2}$. 
Из неравенства (\ref{n21}) получаем, что
\begin{equation}
\PRob(Q(H_p) > qn) \leqs \frac\sigma{2}.
\end{equation}

Теперь воспользуемся леммой \ref{l1}, на сей раз неравенством (\ref{l1_2}).
Возьмём в качестве $A$ множество всех графов, для которых $Q(G) > qn$.
Также возьмём $\eps = \frac\sigma{2}$, $\delta = \sqrt{\frac{2}{pnN}}$.
Предположение $pnN - \sqrt{2pnN} > 0$ означает, что $\delta < 1$.
Заметим, что $1 - \exp\left(-\frac{\delta^2}{2}pnN\right) = 1 - \frac{1}{e} > \frac{1}{2}$, откуда получим, что
\begin{equation}
\PRob\big(G_{\lfloor pnN - \sqrt{2pnN} \rfloor} \in A\big) 
	< 
\frac{\frac\sigma{2}}{1 - \exp\left(-\frac{\delta^2}{2}pnN\right)}
	<
\sigma
\end{equation}
\end{proof}

% модель 2
\section{Модель 2. Выбор степеней клиентов.}
В этой моделе $G_m$ будет устроен немного другим образом. На сей раз, за каждый шаг мы будем равномерно выбирать клиента, 
у которого степень ещё не максимальная, а затем проводить ещё не проведённое ребро от выбранного клиента равномерным образом.
Заметим, что $E(G_m) = m$. Как и в прошлой моделе $G_m$ не очень удобен для исследования, поэтому мы построим граф $H_p$, где $p \in [0,1]$.

Граф $H_p$ строится так: выбираем $J_1, J_2, \dots, J_n$ --- пуассоновские случайные величины с показателем $\lambda = pN$.
$\min(J_k, N)$ --- степень $k$ - го клиента. После того, как все степени клиентов выбраны, 
выбираем нужное количество рёбер равномерным образом. Обозначим $J = \sum\limits_{k=1}^n J_k$. Заметим, что $E(H_p) \leqs J$.

%лемма 2
\begin{lemma} \label{l2}
Возьмём граф $H_p$ при условии того, что $J = m$. 
После этого добавим несколько рёбер тем же способом, который использовался при построении графа $G_m$. 
Добавлять будем до тех пор, пока в графе не окажется ровно $m$ ребер. 
Тогда полученный граф по распределению будет совпадать с графом $G_m$.
\end{lemma}
\begin{proof}
Для начала заметим, что мы можем следить только за распределением степеней клиентов, 
поскольку ребра из них во всех случаях проводятся равномерно. В частности когда мы строили $G_m$, 
мы могли сначала выбрать все степени клиентов, и только после этого начать проводить рёбра.

Заметим, что мы знаем, что $J_1, J_2, \dots, J_n$ при условии $J = m$ имеет мультиномиальное распределение 
$Multinom(m, p_i=\frac{1}{n}) = (Z_1, Z_2, \dots, Z_n)$. Значит, распределение степеней графа $H_p$ при условии $J = m$ такое же,
как у вектора $Z_{\min} = (\min(Z_1, N), \min(Z_2, N), \dots, \min(Z_n, N))$.
Попробуем описать словами этот случайный вектор.

Пусть у нас есть $n$ которобок. Мы берём $m$ шариков, и начинаем равномерно кидать их по коробкам. 
После этого во всех коробках, в которых оказалось больше $N$ шариков, лишние выкидываются.
Распределение количеств шариков в коробках как раз будет $Z_{\min}$. 

Вернемся к тому, как мы модифицируем граф $H_p$. Мы начинаем с вектора $Z_{\min}$ и начинаем докидывать шарики в коробки, 
равномерно по тем коробкам, в которых меньше $N$ шариков. Останавливаемся мы тогда, когда всего шариков будет ровно $m$ штук.

Заметим, что это то же самое, если с самого начала загадать число $m$, кидать шарики в коробки равномерно, 
но при этом, если в коробке, в которую мы кидаем шарик, уже $N$ шариков, то шарик пропадает. 
Останавливаемся мы в тот момент, когда в коробках будет ровно $m$ шариков. 
Нетрудно понять, что то же самое происходит и с распределением степеней графа $G_m$.
\end{proof}

\begin{cons} \label{cons_1}
Условие $J = m$ в лемме можно заменить на $J \leqs m$.
\end{cons}
\begin{proof}
Очевидно из доказательства леммы.
\end{proof}

\begin{proof}[Отступление]
Вернёмся к графу $H_p$ и посмотрим как часто происходит следующее событие: $\PRob(\exists k : J_k \geqs N)$.
Обозначим за $s(p, N) = \PRob(X \geqs N)$, где $X$ -- пуассоновская случайная величина с показателем $pN$.
Иногда аргументы мы будем опускать и писать просто $s$.
Заметим, что $\PRob(\exists k : J_k \geqs N) \leqs N \cdot s(p, N)$. 
Теперь воспользуемся неравенством (\ref{gr_1}) и получим следующие неравенства:
\begin{align}
&s(p,N) = \PRob(X \geqs N) \leqs \frac{e^{-pN}(e\cdot pN)^N}{N^N} = (e^{1-p} p )^N 
\\ \label{s_1}
&\PRob(\exists k : J_k \geqs N) \leqs N \cdot s(p, N) = N \cdot (e^{1-p} p )^N.
\end{align} 
Предположим, что $p \in [0, \frac{1}{2}]$, тогда $e^{1-p} p \leqs \frac{\sqrt{e}}{2}$, 
поскольку $(e^{1-p} p)'_p = (1-p) e^{1-p} > 0$. Поскольку $N \geqs 100$, то мы получаем, что 
\begin{equation}
s \leqs \left(\frac{\sqrt{e}}{2}\right)^N \leqs \frac{e^{50}}{2^{100}} < 10^{-8}.
\end{equation}
Аналогичным образом получаем, что 
\begin{equation}
\PRob(\exists k : J_k \geqs N) \leqs N \cdot \left(\frac{\sqrt{e}}{2}\right)^N
\leqs 100 \cdot \left(\frac{\sqrt{e}}{2}\right)^{100} < 10^{-6}.
\end{equation}
Тем самым мы поняли, что если $p \in [0, \frac{1}{2}]$, то $s$ и $\PRob(\exists k : J_k \geqs N)$ достаточно маленькие.
\end{proof}

Теперь вернёмся к графу $H_p$ и докажем лемму, аналогичную лемме \ref{l1}.

%лемма 3
\begin{lemma} \label{l3}
Пусть $A$ - множество всех графов, который обладают некоторым монотонным свойством, а $\delta \in (0,1)$.
Тогда, если $\PRob( H_p \in A) \geqs 1 - \eps$, то
\begin{equation} \label{l3_1}
\PRob(G_{\lceil pnN(1+\delta) \rceil} \in A) > 1 - \frac{\eps}{1 - \exp\left(-\frac{\delta^2}{4}pnN\right)};
\end{equation}
a если $\PRob( H_p \in A) \leqs \eps$, то
\begin{equation}\label{l3_2}
\PRob(G_{\lfloor pnN(1-\delta) \rfloor} \in A) < \frac{\eps}{1 - Ns - \exp\left(-\frac{\delta^2}{4}pnN\right)};
\end{equation}
\end{lemma}

\begin{proof}
Доказательство полностью аналогично доказательству леммы \ref{l1}, надо только применять следствие \ref{cons_1} из леммы \ref{l2}
и доказать следующие неравенства, 
аналогичные неравенствам (\ref{l1_3} - \ref{l1_4}) и (\ref{l1_5}) леммы \ref{l1}:
\begin{align} \label{l3_3}
\PRob\big( E(H_p) \leqs m \big) &> 1 - \exp\left(-\frac{\delta^2}{4}pnN\right)
\\ \label{l3_4}
\PRob\big( E(H_p) \geqs l \big) &> 1 - Ns - \exp\left(-\frac{\delta^2}{4}pnN\right),
\end{align}
где $m = \lceil pnN(1+\delta) \rceil$ a  $l = \lfloor pnN(1-\delta) \rfloor$.

Докажем неравенство (\ref{l3_3}). Вспомним, что $E(H_p) \leqs J$, где $J = \sum\limits_{k = 1}^n J_k$. Заметим, что
\begin{equation}\label{l3_5}\begin{aligned}
\PRob\big( E(H_p) \leqs m \big) > \PRob\big( J < m \big) \geqs \PRob\big( J < pnN(1+\delta) \big) 
=
\\
= 
1 - \PRob\big( J \geqs pnN(1+\delta) \big) \geqs 1 - \frac{e^{-pnN}(epnN)^{pnN(1+\delta)}}{(pnN(1+\delta))^{pnN(1+\delta)}}
=
\\
=
1 - \left( \frac{e^{-1} e^{1+\delta}(pnN)^{1+\delta}}{(pnN)^{1+\delta}(1+\delta)^{1+\delta}} \right)^{pnN}
=
1 - \left( \frac{e^\delta}{(1+\delta)^{1+\delta}} \right)^{pnN}
\end{aligned}\end{equation}
где в последнем неравенстве было замечено, что $J$ --- пуассоновская случайная величина с показателем $pnN$, 
и было применяно неравенство (\ref{gr_1}).
Теперь заметим, что 
\begin{equation}\begin{aligned}
&\PRob\big( E(H_p) \leqs m \big) > 1 - \left( \frac{e^\delta}{(1+\delta)^{1+\delta}} \right)^{pnN}
=
\\
=
&1 - \exp\big(pnN \cdot (\delta - (1+\delta) \ln(1+\delta)) \big)
\geqs
 1 - \exp\left(-\frac{\delta^2}{4}pnN\right),
\end{aligned}\end{equation}
где мы применили неравенство $\delta - (1+\delta) \ln(1+\delta) \leqs - \frac{\delta^2}{4}$, 
которое верно для $\delta \in (0,1)$. Тем самым неравенство (\ref{l3_3}) доказано.

Теперь докажем неравенство (\ref{l3_4}). Пусть $A$ -- событие $\{\exists k : J_k \geqs N\}$.
Вспомним, что $\PRob(A) \leqs Ns$, что сказано в неравенстве (\ref{s_1}). Заметим, что
\begin{equation}\begin{aligned}
\PRob\big( E(H_p) &\geqs l \big) = 
	\PRob\big(E(H_p) \geqs l | A\big) \cdot \PRob(A) + \PRob\big(E(H_p) \geqs l | \overline{A}\big) \cdot \PRob(\overline{A})
\geqs
\\
\geqs
&\PRob\big(J \geqs l | \overline{A}\big) \cdot \PRob(\overline{A})
	=
\PRob\big(J \geqs l \cap \overline{A} \big) 
	\geqs
\PRob\big(J \geqs l \big) - \PRob(A),
\end{aligned}\end{equation}
поскольку при условии $\overline{A}$, $E(H_p) = J$. Продолжим оценивать:
\begin{equation}\begin{aligned}
\PRob\big( E(H_p) \geqs l \big) 
	\geqs 
\PRob\big(J \geqs l \big) - \PRob(A) 
	>
\PRob\big(J > l \big) - Ns
	\geqs
\\
	\geqs
\PRob\big(J > pnN(1-\delta) \big) - Ns
	=
1 - Ns - \PRob\big( J \leqs pnN(1-\delta)  \big).
\end{aligned}\end{equation}
Теперь аналогично (\ref{l3_5}) используя неравенство (\ref{gr_2}) получаем:
\begin{equation}\begin{aligned}
\PRob\big( J \leqs pnN(1-\delta) \big) 
	\leqs
\frac{
	e^{-pnN}(epnN)^{pnN(1-\delta)}
}{
	(pnN(1-\delta))^{pnN(1-\delta)}
}
	=
\left( \frac{e^{-\delta}}{(1-\delta)^{(1-\delta)}} \right)^{pnN}
	=
\\
	=
\exp\big(pnN \cdot (-\delta - (1-\delta)\ln(1-\delta)) \big)
	<
\exp\left(-\frac{\delta^2}{4}pnN\right),
\end{aligned}\end{equation}
где в последнем переходе использовалось неравенство $-\delta - (1-\delta)\ln(1-\delta) < - \frac{\delta^2}{4}$, 
которое верно при $\delta \in (0,1)$. Неравенство (\ref{l3_4}) доказано, а значит и лемма тоже.

\end{proof}

\end{document}
